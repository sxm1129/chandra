{
  "id": "chatcmpl-45a2ea866e4845fda746182a6b500376",
  "object": "chat.completion",
  "created": 1763370274,
  "model": "chandra",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "<div>\n<h2>Figure 1: The Transformer - model architecture</h2>\n<img alt=\"Diagram of the Transformer model architecture. The model consists of an Encoder stack (left) and a Decoder stack (right), both composed of N identical layers. The Encoder takes Inputs, which are added to Input Embedding and Positional Encoding. Each layer in the Encoder stack contains a Multi-Head Attention block followed by a Feed Forward block, both preceded by Add &amp; Norm. The Decoder takes Outputs (shifted right), which are added to Output Embedding and Positional Encoding. Each layer in the Decoder stack contains a Masked Multi-Head Attention block, followed by a Multi-Head Attention block, and then a Feed Forward block, all preceded by Add &amp; Norm. The Decoder output is passed through a Linear layer and a Softmax layer to produce Output Probabilities.\"/>\n<p>Diagram of the Transformer model architecture. The model consists of an Encoder stack (left) and a Decoder stack (right), both composed of N identical layers. The Encoder takes Inputs, which are added to Input Embedding and Positional Encoding. Each layer in the Encoder stack contains a Multi-Head Attention block followed by a Feed Forward block, both preceded by Add &amp; Norm. The Decoder takes Outputs (shifted right), which are added to Output Embedding and Positional Encoding. Each layer in the Decoder stack contains a Masked Multi-Head Attention block, followed by a Multi-Head Attention block, and then a Feed Forward block, all preceded by Add &amp; Norm. The Decoder output is passed through a Linear layer and a Softmax layer to produce Output Probabilities.</p>\n<h3>3.1 Encoder and Decoder Stacks</h3>\n<p><b>Encoder:</b> The encoder is composed of a stack of <math>N = 6</math> identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection [1] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is <math>\\text{LayerNorm}(x + \\text{Sublayer}(x))</math>, where <math>\\text{Sublayer}(x)</math> is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension <math>d_{\\text{model}} = 512</math>.</p>\n<p><b>Decoder:</b> The decoder is also composed of a stack of <math>N = 6</math> identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position <math>i</math> can depend only on the known outputs at positions less than <math>i</math>.</p>\n<h3>3.2 Attention</h3>\n<p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum</p>\n</div>",
        "refusal": null,
        "annotations": null,
        "audio": null,
        "function_call": null,
        "tool_calls": [],
        "reasoning_content": null
      },
      "logprobs": null,
      "finish_reason": "stop",
      "stop_reason": null,
      "token_ids": null
    }
  ],
  "service_tier": null,
  "system_fingerprint": null,
  "usage": {
    "prompt_tokens": 2799,
    "total_tokens": 3555,
    "completion_tokens": 756,
    "prompt_tokens_details": null
  },
  "prompt_logprobs": null,
  "prompt_token_ids": null,
  "kv_transfer_params": null
}